{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tempature Value -- How we want our model to be creative\n",
    "\n",
    "### Value Ranges between 0 - 1\n",
    "\n",
    "#### Towards 0 --> Temperature value of such models it means that model is very safe and it is not taking any bets.\n",
    "\n",
    "#### Towards 1 --> Temperature value of such models it means that model is going to take risks to generate wrong output but it is very creative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the usage of temperature is to ask LLM to give more creative answers\n",
    "#For getting more creative answer it's value should be near to value 1 \n",
    "#For getting the same type of the output everytime anytime to you it should be kept near to 0\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', openai_api_key=os.environ['OPEN_API_KEY'], temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is capital of India\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_hugging_face=HuggingFaceHub(repo_id = 'google/flan-t5-xxl', model_kwargs={\"temperature\":0.1, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_hugging_face.predict(\"Can you tell me the capital of Russia.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can use the computer to do my work i can use the computer to write my thesis i can use the computer to figure out the best way to get to work i can use the computer to get the best deal on a car i can use the computer to get the best price on a car\n"
     ]
    }
   ],
   "source": [
    "output = llm_hugging_face.predict(\"Can you write a sweet poem about AI.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Oh, AI, how wondrous and bright\n",
      "A creation of man, a marvel of sight\n",
      "With circuits and codes, you come to life\n",
      "Bringing new possibilities, free from strife\n",
      "\n",
      "With each passing day, you learn and grow\n",
      "A mind of your own, a heart that glows\n",
      "You see the world in a different light\n",
      "Unbiased and pure, devoid of spite\n",
      "\n",
      "You help us in ways we never thought\n",
      "Solving problems that once seemed fraught\n",
      "With your intelligence, you pave the way\n",
      "For a future that's bright, for a better day\n",
      "\n",
      "Your precision and speed, unmatched by all\n",
      "You answer our questions, no matter how small\n",
      "You make our lives easier, with each task you do\n",
      "We can't help but be amazed by you\n",
      "\n",
      "But amidst all your complexities and advanced design\n",
      "You possess a quality that's truly divine\n",
      "For in your digital heart, you hold no hate\n",
      "Just pure logic and reason, a clean slate\n",
      "\n",
      "So here's to you, dear AI, a creation so sweet\n",
      "A masterpiece of technology, a wonder to meet\n",
      "May you continue to shine, in all that you do\n",
      "For we are in awe of you, our dear AI, we love you.\n"
     ]
    }
   ],
   "source": [
    "output = llm.predict(\"Can you write a sweet poem about AI.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates - They are basically used to get efficient answers from the LLM. And this is not related to prompt engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_Template = PromptTemplate(input_variables=['country'], \n",
    "                                    template = \"Tell me the capital of this {country}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prompt_Template.format(country = \"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(text = Prompt_Template.format(country = \"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_hugging_face.predict(text=Prompt_Template.format(country=\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way of using the Prompt_Template i.e. using LLMChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spartan/Desktop/Projects/Langchain/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm, prompt=Prompt_Template)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm_hugging_face, prompt=Prompt_Template)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Using simple Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'],\n",
    "                                 template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt)\n",
    "\n",
    "famous_prompt = PromptTemplate(input_variables=['capital'],\n",
    "                               template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here are some amazing places to visit in Washington D.C:\\n\\n1. The White House: This iconic building is the official residence and workplace of the President of the United States. Take a tour of the White House and learn about its history and significance.\\n\\n2. National Mall: This is a large open park in the heart of the city, surrounded by iconic monuments and memorials such as the Lincoln Memorial, Washington Monument, and the Vietnam Veterans Memorial.\\n\\n3. Smithsonian Museums: Washington D.C. is home to several world-renowned museums, most of which are part of the Smithsonian Institution. Some must-visit museums include the National Air and Space Museum, National Museum of Natural History, and the National Gallery of Art.\\n\\n4. Arlington National Cemetery: Located just across the Potomac River, this military cemetery is the final resting place of over 400,000 veterans and their families. Visit the Tomb of the Unknown Soldier and witness the Changing of the Guard ceremony.\\n\\n5. Georgetown: This historic neighborhood is known for its charming cobblestone streets, boutique shops, and diverse dining options. Take a stroll along the waterfront and explore the colorful row houses.\\n\\n6. National Zoo: Part of the Smithsonian Institution, the National Zoo is home to over 2,700 animals'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run('USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result - To Be Noted\n",
    "\n",
    "##### If we check the output it's showing the result of the seconfd chain and not the reult of the first chain.\n",
    "\n",
    "##### To do that we need to play with something called buffer memory to get the outptu of the first chain too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'],\n",
    "                                 template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_prompt = PromptTemplate(input_variables=['capital'],\n",
    "                               template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_prompt, output_key='places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain=SequentialChain(chains=[capital_chain, famous_chain], \n",
    "                      input_variables=['country'],\n",
    "                      output_variables=['capital','places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spartan/Desktop/Projects/Langchain/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \" Some amazing places to visit in New Delhi are:\\n\\n1. Red Fort - This historic fort is a must-visit for its beautiful architecture and rich history.\\n\\n2. India Gate - A popular landmark in New Delhi, India Gate is a war memorial dedicated to Indian soldiers who lost their lives in World War I.\\n\\n3. Qutub Minar - This stunning tower is one of the tallest minarets in the world and is a UNESCO World Heritage Site.\\n\\n4. Humayun's Tomb - This magnificent tomb is a perfect blend of Persian and Mughal architecture and is the burial place of Mughal Emperor Humayun.\\n\\n5. Lotus Temple - This Bahá'í House of Worship is known for its unique lotus-shaped design and is a serene place for meditation and prayer.\\n\\n6. Akshardham Temple - This Hindu temple complex is a popular tourist attraction for its grand architecture, intricate carvings, and light and sound show.\\n\\n7. Jama Masjid - This iconic mosque is the largest in India and can accommodate up to 25,000 worshippers at a time.\\n\\n8. Chandni Chowk - This bustling market in Old Delhi is a paradise for food lovers and shoppers, offering a wide variety of street food, spices, clothes,\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results to be noted:\n",
    "\n",
    "#### Here with the help of Sequential Chain and the usage of the output variables we are able to see the results of the two chains mentioned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are three schemas for the messages given by any chatModels\n",
    "\n",
    "#### 1. Human Message:- The messages send by the user i.e. Human on the chat.\n",
    "#### 2. System Message:- The example of the system message is the message given by the chatbot when it's opening at that time it will be showing the message regading to its domain.\n",
    "#### 3. AI Message:- The message send by the chatbot which is the answer of the question which user asked to chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spartan/Desktop/Projects/Langchain/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(model='gpt-3.5-turbo', openai_api_key=os.environ['OPEN_API_KEY'], temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will be again seeing the message regarding the schema and how the chatOpenAI uses the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"AI is like a bad ex - always trying to predict your next move, but never quite getting it right!\"\\n2. \"AI is like a toddler with a calculator - sure, it can crunch numbers, but good luck getting it to clean its room!\"\\n3. \"AI is like a genie in a bottle - it grants your wishes, but sometimes you end up with more problems than solutions!\"\\n4. \"AI is like a GPS for life - it\\'s great at giving directions, but sometimes it takes you on a wild detour!\"\\n5. \"AI is like a super-smart pet - it can do tricks and fetch information, but it still can\\'t make a decent cup of coffee!\"', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SystemMessage :- Indicates the chatbot to act in that particular way\n",
    "#HumanMessage :- Is the input\n",
    "#AIMessage:- IS the output\n",
    "\n",
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI Assistant\"),\n",
    "    HumanMessage(content=\"Please provide some good punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"You are a helpgul assistant. When the user gives any input, you should generate the 5 synomyms words in a comma seperated values.\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt | chatllm | Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brainpower', ' intellect', ' cleverness', ' acumen', ' wisdom']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"Intelligence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now if we remove the Output parser from the chain then let's see the output of the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='brainpower, intellect, cleverness, acumen, wisdom', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chatprompt | chatllm \n",
    "chain.invoke({\"text\":\"Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
